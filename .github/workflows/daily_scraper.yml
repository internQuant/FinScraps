name: Daily Scraper (UTC-3 at 23:00, Mon-Fri)

on:
  schedule:
    # 02:00 UTC, Tuesday through Saturday
    # which corresponds to 23:00 UTC-3, Monday through Friday
    - cron: '0 2 * * 2-6'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          ref: auto-scraping
          fetch-depth: 0               # full history to avoid unrelated-histories
          persist-credentials: true     # keep token so we can push

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Configure Git Identity
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Merge from prod-scraping
        run: |
          set -euo pipefail
          git fetch origin prod-scraping --prune
          # Try a normal merge first; if histories are unrelated, allow it explicitly.
          if ! git merge --no-ff origin/prod-scraping -m "Merge origin/prod-scraping into auto-scraping"; then
            echo "Normal merge failed; retrying with --allow-unrelated-histories"
            git merge --no-ff --allow-unrelated-histories origin/prod-scraping -m "Merge origin/prod-scraping (unrelated histories) into auto-scraping"
          fi

      - name: Run scraper
        run: |
          python auto_scrape.py

      - name: Commit changes (if any)
        run: |
          git add -A
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Daily scrape update"
          fi

      - name: Push changes
        run: |
          # actions/checkout provided credentials; push back to the same branch
          git push origin HEAD:auto-scraping
